{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick and Dirty - Learn how to predict 10 steps out from first 200\n",
    "\n",
    "- Create Loaders\n",
    "- Create Model\n",
    "- Train\n",
    "- Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Loaders / Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import h5py\n",
    "\n",
    "path = \"/Users/anthonypoole/data/local_dqfno/raw_256x256\"\n",
    "\n",
    "def get_list_files(dir, rand=True):\n",
    "    files = os.listdir(dir)\n",
    "    if not rand:\n",
    "        return files\n",
    "    random.shuffle(files)\n",
    "    return files\n",
    "\n",
    "def get_pf_steps(curr_epoch, total_epoch, max_pf_step):\n",
    "    # First 3 epochs: no iterative push forward (i.e. one-step prediction only)\n",
    "    initial_phase = 3  \n",
    "    # Last couple epochs: random number of steps (simulate training for multi-step predictions)\n",
    "    final_phase = total_epoch - 2  \n",
    "    if curr_epoch < initial_phase:\n",
    "        return 1\n",
    "    elif curr_epoch >= final_phase:\n",
    "        return random.randint(1, max_pf_step)\n",
    "    else:\n",
    "        # Gradually increase steps linearly from 1 to max_pf_step\n",
    "        steps = 1 + int((max_pf_step - 1) * (curr_epoch - initial_phase) / (final_phase - initial_phase))\n",
    "        return steps\n",
    "\n",
    "def get_chunk(file_path, chunk_size, chunk_index):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        start = chunk_index * chunk_size\n",
    "        end = start + chunk_size\n",
    "        \n",
    "        if start >= f['gamma_n'].shape[0]:\n",
    "            raise IndexError(\"Chunk index is out of range.\")\n",
    "        \n",
    "        n = torch.from_numpy(f['density'][start:end])\n",
    "        e = torch.from_numpy(f['omega'][start:end])\n",
    "        p = torch.from_numpy(f['phi'][start:end])\n",
    "        gn = torch.from_numpy(f['gamma_n'][start:end]).unsqueeze(0)\n",
    "        state = torch.stack((n, e, p)).permute(1, 0, 2, 3).unsqueeze(0).unsqueeze(0)\n",
    "        return (state, gn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQFNO(\n",
       "  (positional_embedding): GridEmbedding2D()\n",
       "  (lifting): ChannelMLP(\n",
       "    (fcs): ModuleList(\n",
       "      (0): Conv1d(3, 3, kernel_size=(1,), stride=(1,))\n",
       "      (1): Conv1d(3, 8, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (fno_blocks): FNOBlocks(\n",
       "    (spectral_convs): ModuleList(\n",
       "      (0-3): 4 x SpectralConv(\n",
       "        (weight): ParameterList(\n",
       "            (0): Parameter containing: [torch.complex64 of size 2x8x8x16x9]\n",
       "            (1): Parameter containing: [torch.complex64 of size 2x8x8x32x17]\n",
       "            (2): Parameter containing: [torch.complex64 of size 2x8x8x8x5]\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv3ds): ModuleList(\n",
       "      (0-3): 4 x Conv3d(8, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (projection): ChannelMLP(\n",
       "    (fcs): ModuleList(\n",
       "      (0): Conv1d(8, 16, kernel_size=(1,), stride=(1,))\n",
       "      (1): Conv1d(16, 1, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (derived_module): DerivedMLP()\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.dqfno import DQFNO\n",
    "\n",
    "config = {\n",
    "    'data_dir': path,\n",
    "    'modes': [[16, 16], [32, 32], [8, 8]],\n",
    "    'in_channels': 1,\n",
    "    'out_channels': 1,\n",
    "    'hidden_channels': 8,  # Change back to 128 if needed\n",
    "    'n_layers': 4,\n",
    "    'dx': 1.0,  # Assign a proper value\n",
    "    'derived_type': 'direct',\n",
    "    'device': 'cpu',\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 0.01,\n",
    "    'losses': ['lp', 'h1', 'derived'],\n",
    "    'loss_weights': [0.4, 0.4, 0.2],\n",
    "    'n_epochs': 10,\n",
    "    'chunk_size': 200,\n",
    "    'max_pf_step': 5  # Maximum push-forward steps\n",
    "}\n",
    "\n",
    "model = DQFNO(\n",
    "    modes=config['modes'],\n",
    "    in_channels=config['in_channels'],\n",
    "    out_channels=config['out_channels'],\n",
    "    hidden_channels=config['hidden_channels'],\n",
    "    n_layers=config['n_layers'],\n",
    "    dx=config['dx'],\n",
    "    derived_type=config['derived_type'],\n",
    ")\n",
    "\n",
    "model.to(config['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 200, 3, 256, 256]) torch.Size([1, 200])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from scripts.utils import create_run_directory, initialize_model, get_loss_object, plot_and_save_loss\n",
    "from src.losses.custom_losses import MultiTaskLoss\n",
    "from src.losses.data_losses import LpLoss, H1Loss\n",
    "from src.data.data_utils import get_data_loader, get_test_loader, PushForwardDataSet, push_forward\n",
    "\n",
    "device = config['device']\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "\n",
    "selector_state = lambda y_pred, y: (y_pred[0], y[0])\n",
    "selector_derived = lambda y_pred, y: (y_pred[1], y[1])\n",
    "\n",
    "losses = []\n",
    "selectors = []\n",
    "for loss, weight in zip(config['losses'], config['loss_weights']):\n",
    "    if loss == 'lp':\n",
    "        losses.append(LpLoss(d=4, p=2, reduction='mean'))\n",
    "        selectors.append(selector_state)\n",
    "    elif loss == 'h1':\n",
    "        losses.append(H1Loss(d=2))\n",
    "        selectors.append(selector_state)\n",
    "    elif loss == 'derived':\n",
    "        losses.append(torch.nn.MSELoss())\n",
    "        selectors.append(selector_derived)\n",
    "    \n",
    "loss_obj = MultiTaskLoss(\n",
    "    loss_functions=losses,\n",
    "    scales=config['loss_weights'],\n",
    "    multi_output=True,\n",
    "    input_selectors=selectors\n",
    ")\n",
    "\n",
    "for epoch in range(config['n_epochs']):\n",
    "    running_loss = 0.0\n",
    "    # Loop through all files in the data directory\n",
    "    for file in get_list_files(config['data_dir']):\n",
    "        # Pass in total epochs and max_pf_step from config\n",
    "        pf_steps = get_pf_steps(epoch, config['n_epochs'], config['max_pf_step'])\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        file_path = os.path.join(config['data_dir'], file)\n",
    "        input_data = get_chunk(file_path, config['chunk_size'], chunk_index=0)\n",
    "        print(input_data[0].shape, input_data[1].shape)\n",
    "        \n",
    "        # Iteratively push the model forward\n",
    "        for i in range(pf_steps):\n",
    "            input_data = model(input_data)\n",
    "        \n",
    "        # Use the output after push-forward steps as prediction.\n",
    "        # We choose the target chunk based on the number of steps (i.e. the next chunk)\n",
    "        target_chunk_index = pf_steps  # (since pf_steps was the number of model iterations)\n",
    "        target_data = get_chunk(file_path, config['chunk_size'], chunk_index=target_chunk_index)\n",
    "        \n",
    "        loss = loss_obj(input_data, target_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += float(loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{config['n_epochs']} Loss: {running_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dqfno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
